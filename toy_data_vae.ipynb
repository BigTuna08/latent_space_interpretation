{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "- Notebook for creating and training a variational autoencoder to use with the toy sequence dataset\n",
    " - To create the dataset, run toy_data_dataset.ipynb\n",
    "- Settings in the Parameters section (below) are used in creating and training the network  \n",
    " - Comment one of the versions (Full/Quick) of settings out below, or set them how you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "save_loc = \"saved/toy_seqs\"\n",
    "\n",
    "\n",
    "\n",
    "## Full\n",
    "reps = 1  # number of times to try each parameter setting \n",
    "ep = 60  # max epochs \n",
    "EARLY_STOP = 3  # stop if no improvement in this many epochs\n",
    "BATCH_SIZE= 32    # batch size\n",
    "\n",
    "layer_size_options = [[256, 16], [512, 64, 16], [1024, 64]]\n",
    "latent_dim_options = [4, 6, 8]\n",
    "learning_rate_options = [5e-5]\n",
    "optimizer_options = [tf.keras.optimizers.Adam]\n",
    "\n",
    "\n",
    "# Quick \n",
    "reps = 1\n",
    "ep = 3 \n",
    "EARLY_STOP = 3\n",
    "BATCH_SIZE= 32\n",
    "\n",
    "layer_size_options = [[256, 16]]\n",
    "latent_dim_options = [4]\n",
    "learning_rate_options = [5e-5]\n",
    "optimizer_options = [tf.keras.optimizers.Adam]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from my_lib.save_load import load_datasets, save_seq_vae\n",
    "from my_lib.models.vae_sequence import VAE, SCALE, START, loss_function, acc_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load .ipynb_checkpoints (This is probably fine, unless it's needed)\n",
      "\n",
      "Columns of s are: start, stop, step, length\n",
      "\n",
      "initialized variable, s_cv\n",
      "initialized variable, s_tr\n",
      "\n",
      "Max seq lenght is 29.0\n"
     ]
    }
   ],
   "source": [
    "all_data = load_datasets(save_loc)\n",
    "bs = BATCH_SIZE\n",
    "print(\"\\nColumns of s are: start, stop, step, length\\n\")\n",
    "for name, model in all_data.items():\n",
    "    name = name.split(\".\")[0]\n",
    "    exec(\"{} = model\".format(name))\n",
    "    print(\"initialized variable,\", name)\n",
    "    \n",
    "max_len = max(s_tr[:,-1])\n",
    "print(\"\\nMax seq lenght is\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = []\n",
    "for s in (s_tr, s_cv):\n",
    "    eff_stops = s[:,0] + s[:, 2]*max_len\n",
    "    expanded_seqs = [(x[0],eff_s, x[2] ) for x, eff_s in zip(s, eff_stops)]\n",
    "    all_seqs.append(expanded_seqs)\n",
    "    \n",
    "    \n",
    "all_seqs_tr, all_seqs_cv = all_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train = tf.keras.preprocessing.sequence.pad_sequences([np.arange(*x) for x in all_seqs_tr], \n",
    "                                                          padding='post')\n",
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_val = tf.keras.preprocessing.sequence.pad_sequences([np.arange(*x) for x in all_seqs_cv], \n",
    "                                                          padding='post')\n",
    "input_tensor_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_train = tf.cast(input_tensor_train.reshape(*input_tensor_train.shape, 1), tf.float32)\n",
    "input_tensor_val = tf.cast(input_tensor_val.reshape(*input_tensor_val.shape, 1), tf.float32)\n",
    "\n",
    "\n",
    "seq_lens_train = tf.constant(s_tr[:,-1], dtype=tf.float32)\n",
    "seq_lens_val = tf.constant(s_cv[:,-1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train/SCALE, seq_lens_train)) \\\n",
    "                         .shuffle(len(input_tensor_train)) \\\n",
    "                         .batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_cv = tf.data.Dataset.from_tensor_slices((input_tensor_val/SCALE, seq_lens_val)) \\\n",
    "                            .shuffle(len(input_tensor_val)) \\\n",
    "                            .batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reconsturction(ae, max_show=10, teacher_forcing=True, cv_data=True):\n",
    "\n",
    "    encoder= ae.encoder\n",
    "    decoder = ae.decoder\n",
    "    BATCH_SIZE = 32\n",
    "    sentances = [[] for _ in range(BATCH_SIZE)]\n",
    "\n",
    "    if cv_data:\n",
    "        for (inp, true_lens) in dataset_cv: break # hacky way to get inp, targ\n",
    "    else:\n",
    "        for (inp, true_lens) in dataset: break # hacky way to get inp, targ\n",
    "    to_translate = np.zeros(inp.shape)\n",
    "\n",
    "    loss = 0\n",
    "    acc = tf.constant([0,0], dtype=tf.float32)\n",
    "\n",
    "    masked_inp = inp*tf.expand_dims(tf.sequence_mask(true_lens, dtype=tf.float32, maxlen=inp.shape[1]),-1)\n",
    "    context, _, _  = encoder(masked_inp)\n",
    "    \n",
    "    dec_input = tf.expand_dims([START] * ae.batch_size, 1)\n",
    "    dec_hidden = ae.initialize_hidden_state()\n",
    "\n",
    "    pred_list = []\n",
    "    pred_lens = tf.minimum(tf.round(ae.len_decoder(context)),inp.shape[1])\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(inp.shape[1]):\n",
    "        # passing enc_output to the self.decoder\n",
    "        predictions, dec_hidden, = decoder((dec_input, context, dec_hidden))\n",
    "\n",
    "        loss += loss_function(inp[:, t], predictions , pred_lens)\n",
    "        acc += acc_metric(inp[:, t], predictions)\n",
    "\n",
    "        # using teacher forcing\n",
    "        \n",
    "        to_translate[:,t] = predictions\n",
    "        \n",
    "        if teacher_forcing:\n",
    "            dec_input = inp[:, t]\n",
    "        else:\n",
    "            dec_input = predictions\n",
    "            \n",
    "        pred_list.append(predictions)\n",
    "\n",
    "    batch_loss = (loss / int(inp.shape[1]))\n",
    "\n",
    "    \n",
    "    print(\"*\"*100)\n",
    "    print(\"acc\", 1- acc[0]/acc[1])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    for i in range(min(max_show, len(inp))):\n",
    "\n",
    "        true = [x[0] for x in tf.round(inp[i]*SCALE).numpy() ]#if x[0] > 0]\n",
    "        pred = [x[0] for x in tf.round(to_translate[i]*SCALE).numpy()] #[:int(pred_lens[i])]\n",
    "\n",
    "        true_fin = False\n",
    "        pred_fin = False\n",
    "\n",
    "        for seq_i, (t,p) in enumerate(zip(true, pred)):\n",
    "            if seq_i < true_lens[i]: \n",
    "                t = str(int(t))\n",
    "            else:\n",
    "                t = \"   \"\n",
    "                true_fin = True\n",
    "            if seq_i < pred_lens[i]:\n",
    "                p = str(int(p))\n",
    "            else:\n",
    "                p = \"   \"\n",
    "                pred_fin = True\n",
    "\n",
    "            if true_fin and pred_fin:\n",
    "                break\n",
    "\n",
    "            print(\"{} ----> {}\".format(t, p))\n",
    "\n",
    "        true_s = \"\\t\".join(map(str,map(int, true)))\n",
    "        pred_s = \"\\t\".join(map(str,map(int, pred)))\n",
    "\n",
    "\n",
    "        print()\n",
    "        print(\"true step:\", true[1]-true[0])\n",
    "        print(\"mean pred step {:.2f}\".format(np.mean(np.diff(pred[:int(pred_lens[i])]))))\n",
    "        print(\"median pred step {:.2f}\".format(np.median(np.diff(pred[:int(pred_lens[i])]))))\n",
    "\n",
    "        tl = true_lens[i].numpy()\n",
    "        pl = pred_lens[i].numpy()[0]\n",
    "        print(\"True length:\",  tl)\n",
    "        print(\"Predicted length:\", pl)\n",
    "\n",
    "        print(\"\\n\", \"*\"*100 ,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_ae(ae, EPOCHS, EARLY_STOP=4, ppe = 2, no_tf_p=0.02, big_update_every=4):\n",
    "    \n",
    "    steps_per_epoch = len(dataset) \n",
    "    steps_per_epoch_cv = len(dataset_cv) \n",
    "    \n",
    "    print_every = steps_per_epoch // ppe\n",
    "    full_start = time.time()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        update_count = 0 \n",
    "        start = time.time()\n",
    "\n",
    "        total_loss, cv_total_loss = 0, 0\n",
    "        total_acc, cv_total_acc = 0,0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset):\n",
    "            \n",
    "            # randomly choose if using teacher forcing\n",
    "            if np.random.random() > no_tf_p:\n",
    "                batch_loss, batch_mets = ae.train_step(inp, targ)\n",
    "            else:\n",
    "                batch_loss, batch_mets = ae.train_step_tf(inp, targ)\n",
    "\n",
    "            total_loss += batch_loss\n",
    "\n",
    "\n",
    "            if batch % print_every == 0:\n",
    "                update_count += 1\n",
    "                print('Epoch {} update {} (Batch {}) Loss {:.4f}'.format(epoch + 1,\n",
    "                                                                         update_count,\n",
    "                                                             batch,\n",
    "                                                             batch_loss.numpy()))\n",
    "                \n",
    "                for name, val in batch_mets:\n",
    "                    print('Epoch {} update {} (Metric={}) val={:.4f}'.format(epoch + 1,\n",
    "                                                                            update_count,\n",
    "                                                     name,\n",
    "                                                     val))\n",
    "                \n",
    "            \n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch) )\n",
    "        print('Epoch {} Acc {:.4f}'.format(epoch + 1, total_acc / steps_per_epoch))\n",
    "\n",
    "        ae.track[\"loss_tr\"].append(total_loss / steps_per_epoch)\n",
    "        ae.track[\"acc_tr\"].append(total_acc / steps_per_epoch)\n",
    "\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset_cv.take(steps_per_epoch_cv)):\n",
    "\n",
    "            batch_loss, batch_mets = ae.cv_step(inp, targ)\n",
    "            cv_total_loss += batch_loss  \n",
    "\n",
    "            if batch == 0:\n",
    "                cv_info = {}\n",
    "                for name, val in batch_mets:\n",
    "                    name = name.numpy().decode(\"utf-8\")\n",
    "                    cv_info[name] = val                    \n",
    "            else:\n",
    "                for name, val in batch_mets:\n",
    "                    name = name.numpy().decode(\"utf-8\")\n",
    "                    cv_info[name] += val\n",
    "                \n",
    "\n",
    "        print('**CV** Epoch {} Loss {:.4f}'.format(epoch + 1, cv_total_loss / steps_per_epoch_cv))\n",
    "\n",
    "        ae.track[\"loss_cv\"].append(cv_total_loss / steps_per_epoch_cv)\n",
    "        \n",
    "        for name, val in cv_info.items():\n",
    "\n",
    "\n",
    "            print('Epoch {} update {} (Metric={}) val={:.4f}'.format(epoch + 1,\n",
    "                                                                    update_count,\n",
    "                                                                     name,\n",
    "                                                                     val / steps_per_epoch_cv))\n",
    "\n",
    "\n",
    "        print('Time taken for 1 epoch {} sec\\n\\n'.format(time.time() - start))\n",
    "        \n",
    "\n",
    "\n",
    "        if len(ae.track[\"loss_cv\"]) > EARLY_STOP and min(ae.track[\"loss_cv\"]) < min(ae.track[\"loss_cv\"][-EARLY_STOP:]):\n",
    "            print(\"\\nEarly stop, best loss\", min(ae.track[\"loss_cv\"]), \"last\", EARLY_STOP, ae.track[\"loss_cv\"][-EARLY_STOP:])\n",
    "            break \n",
    "\n",
    "            \n",
    "        if big_update_every:\n",
    "            if epoch % big_update_every == 0:\n",
    "\n",
    "                show_reconsturction(ae, max_show=2)\n",
    "                print(\"without teacher forcing\")\n",
    "                show_reconsturction(ae, max_show=2, teacher_forcing=False)\n",
    "\n",
    "\n",
    "\n",
    "    print('\\n\\nFull Time taken for {} epochs is {} sec\\n\\n'.format(epoch, time.time() - full_start))\n",
    "\n",
    "    return ae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********\tBegin trial\t0\t********\t\t\n",
      "Time taken for trace (train):\t\t50.61\n",
      "\n",
      "Time taken for trace (train):\t\t49.17\n",
      "\n",
      "Epoch 1 update 1 (Batch 0) Loss 370.8275\n",
      "Epoch 1 update 1 (Metric=b'acc_m') val=0.0000\n",
      "Epoch 1 update 1 (Metric=b'kl_m') val=0.0011\n",
      "Epoch 1 update 1 (Metric=b'len_m') val=4.8295\n",
      "Epoch 1 update 1 (Metric=b'recons_m') val=365.9969\n",
      "Time taken for trace (train):\t\t48.93\n",
      "\n",
      "Epoch 1 update 2 (Batch 1484) Loss 19.8129\n",
      "Epoch 1 update 2 (Metric=b'acc_m') val=0.0097\n",
      "Epoch 1 update 2 (Metric=b'kl_m') val=0.0006\n",
      "Epoch 1 update 2 (Metric=b'len_m') val=3.2486\n",
      "Epoch 1 update 2 (Metric=b'recons_m') val=16.5637\n",
      "Epoch 1 Loss 20.1635\n",
      "Epoch 1 Acc 0.0000\n",
      "Time taken for trace (train):\t\t7.75\n",
      "\n",
      "**CV** Epoch 1 Loss 9.0417\n",
      "Epoch 1 update 2 (Metric=acc_m) val=0.0096\n",
      "Epoch 1 update 2 (Metric=kl_m) val=0.0848\n",
      "Epoch 1 update 2 (Metric=len_m) val=4.6867\n",
      "Epoch 1 update 2 (Metric=recons_m) val=4.2702\n",
      "Time taken for 1 epoch 471.12880182266235 sec\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "acc tf.Tensor(0.0118534565, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "790 ----> 90\n",
      "823 ----> 478\n",
      "856 ---->    \n",
      "889 ---->    \n",
      "922 ---->    \n",
      "955 ---->    \n",
      "988 ---->    \n",
      "1021 ---->    \n",
      "1054 ---->    \n",
      "1087 ---->    \n",
      "1120 ---->    \n",
      "1153 ---->    \n",
      "1186 ---->    \n",
      "1219 ---->    \n",
      "1252 ---->    \n",
      "1285 ---->    \n",
      "1318 ---->    \n",
      "1351 ---->    \n",
      "1384 ---->    \n",
      "\n",
      "true step: 33.0\n",
      "mean pred step 388.00\n",
      "median pred step 388.00\n",
      "True length: 19.0\n",
      "Predicted length: 2.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "524 ----> 88\n",
      "543 ---->    \n",
      "562 ---->    \n",
      "581 ---->    \n",
      "600 ---->    \n",
      "619 ---->    \n",
      "638 ---->    \n",
      "657 ---->    \n",
      "676 ---->    \n",
      "695 ---->    \n",
      "714 ---->    \n",
      "733 ---->    \n",
      "752 ---->    \n",
      "771 ---->    \n",
      "790 ---->    \n",
      "\n",
      "true step: 19.0\n",
      "mean pred step nan\n",
      "median pred step nan\n",
      "True length: 15.0\n",
      "Predicted length: 1.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "without teacher forcing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "acc tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "676 ----> 91\n",
      "711 ----> 113\n",
      "746 ---->    \n",
      "781 ---->    \n",
      "816 ---->    \n",
      "851 ---->    \n",
      "886 ---->    \n",
      "921 ---->    \n",
      "956 ---->    \n",
      "991 ---->    \n",
      "1026 ---->    \n",
      "1061 ---->    \n",
      "1096 ---->    \n",
      "1131 ---->    \n",
      "1166 ---->    \n",
      "1201 ---->    \n",
      "1236 ---->    \n",
      "1271 ---->    \n",
      "1306 ---->    \n",
      "1341 ---->    \n",
      "\n",
      "true step: 35.0\n",
      "mean pred step 22.00\n",
      "median pred step 22.00\n",
      "True length: 20.0\n",
      "Predicted length: 2.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "348 ----> 88\n",
      "374 ---->    \n",
      "400 ---->    \n",
      "426 ---->    \n",
      "\n",
      "true step: 26.0\n",
      "mean pred step nan\n",
      "median pred step nan\n",
      "True length: 4.0\n",
      "Predicted length: 1.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "Epoch 2 update 1 (Batch 0) Loss 8.3715\n",
      "Epoch 2 update 1 (Metric=b'acc_m') val=0.0097\n",
      "Epoch 2 update 1 (Metric=b'kl_m') val=0.0458\n",
      "Epoch 2 update 1 (Metric=b'len_m') val=4.6982\n",
      "Epoch 2 update 1 (Metric=b'recons_m') val=3.6275\n",
      "Epoch 2 update 2 (Batch 1484) Loss 7.0909\n",
      "Epoch 2 update 2 (Metric=b'acc_m') val=0.0065\n",
      "Epoch 2 update 2 (Metric=b'kl_m') val=0.1410\n",
      "Epoch 2 update 2 (Metric=b'len_m') val=4.2537\n",
      "Epoch 2 update 2 (Metric=b'recons_m') val=2.6962\n",
      "Epoch 2 Loss 8.5117\n",
      "Epoch 2 Acc 0.0000\n",
      "**CV** Epoch 2 Loss 3.9051\n",
      "Epoch 2 update 2 (Metric=acc_m) val=0.0096\n",
      "Epoch 2 update 2 (Metric=kl_m) val=0.3104\n",
      "Epoch 2 update 2 (Metric=len_m) val=1.8331\n",
      "Epoch 2 update 2 (Metric=recons_m) val=1.7617\n",
      "Time taken for 1 epoch 215.77419686317444 sec\n",
      "\n",
      "\n",
      "Epoch 3 update 1 (Batch 0) Loss 3.9803\n",
      "Epoch 3 update 1 (Metric=b'acc_m') val=0.0162\n",
      "Epoch 3 update 1 (Metric=b'kl_m') val=0.2527\n",
      "Epoch 3 update 1 (Metric=b'len_m') val=2.2274\n",
      "Epoch 3 update 1 (Metric=b'recons_m') val=1.5003\n",
      "Epoch 3 update 2 (Batch 1484) Loss 2.1920\n",
      "Epoch 3 update 2 (Metric=b'acc_m') val=0.0151\n",
      "Epoch 3 update 2 (Metric=b'kl_m') val=0.2689\n",
      "Epoch 3 update 2 (Metric=b'len_m') val=1.2078\n",
      "Epoch 3 update 2 (Metric=b'recons_m') val=0.7153\n",
      "Epoch 3 Loss 2.7902\n",
      "Epoch 3 Acc 0.0000\n",
      "**CV** Epoch 3 Loss 1.8858\n",
      "Epoch 3 update 2 (Metric=acc_m) val=0.0139\n",
      "Epoch 3 update 2 (Metric=kl_m) val=0.2636\n",
      "Epoch 3 update 2 (Metric=len_m) val=0.9158\n",
      "Epoch 3 update 2 (Metric=recons_m) val=0.7065\n",
      "Time taken for 1 epoch 218.0551517009735 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Full Time taken for 2 epochs is 906.4351170063019 sec\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trial in range(reps):\n",
    "    for hidden_dim in layer_size_options:\n",
    "        for ld in latent_dim_options:\n",
    "            for op in optimizer_options:\n",
    "                for lr in learning_rate_options:\n",
    "                \n",
    "                    opt = op(learning_rate=lr)\n",
    "                    opt.name= opt.get_config()[\"name\"]+ str(lr).replace(\".\", \"_\")\n",
    "\n",
    "                    print(\"\\n\")\n",
    "                    print(\"*\"*8, \"Begin trial\", trial, \"*\"*8, \"\\t\", sep=\"\\t\")\n",
    "                    experiment_start = time.time()\n",
    "\n",
    "\n",
    "                    now = datetime.now()\n",
    "                    time_str = \"-\".join(map(str, [now.year, now.month, now.day, now.hour, now.minute]))\n",
    "\n",
    "                    ld_str = \"_\".join(map(str, hidden_dim)) + \"_{}\".format(ld)\n",
    "                    setting_str = \"bs-{}-ld-{}-ep-{}-opt-{}\".format(bs, ld_str, ep, opt.name)\n",
    "                    id_str = setting_str + \"_\" + time_str\n",
    "\n",
    "\n",
    "\n",
    "                    ae = VAE(inp_shape = input_tensor_train.shape[1:], \n",
    "                            latent_dim=ld,\n",
    "                            hidden_units=hidden_dim,\n",
    "                            batch_size=bs,\n",
    "                            optimizer=opt,\n",
    "                            start_word=START)\n",
    "\n",
    "\n",
    "                    aes.append((id_str, ae))\n",
    "                    train_ae(ae, ep, EARLY_STOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View trained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAABATElEQVR4nO3dd3wVVfr48c+TRoCEEkqANHqvEghd7FgBAUGiYsUCu2757n531/1tcYt+1S26YO8amhV1bajLIi0QkFClk5DQQmiBkH5+f5yJXC6ppMxN8rxfr/vKvTNnzjx3Mvc+c86ZOyPGGJRSSik/twNQSinlGzQhKKWUAjQhKKWUcmhCUEopBWhCUEop5dCEoJRSCnAhIYjIPhG5srbXW5ayYhKRsSKSVtsxqbpFRIyIdHU7DqWqok62EERkmohsF5GTInJERN4QkWbOvEYi8oqIpIhIlohsEJFrazCWGSKyTkROiUiaiDwhIgEe85eKSI6InHYe272WbyMi85z3clxEEiqwzltEZKWIZIvI0hLm+4vIn0XkgLMNvhORFpV4T187X3AB5ZeuOhHpLSJJzvs/LiJfiUjvGlpXx4q+NxHpJCJFIvJcTcRSEc4BSZHH/nNaRGZUob6Bzv6a7fwd6DHvDyKS77WuzuXU111EFotIhogcE5EvRKSHV5mfisgh5zPyqog0cqa3FZH5zn56UkRWiEic17LTnc/yGRH5UETCyoilr7P+oyJywQ+sRGS2s5/lisjrFdhWpZYXkSARedc5mDQiMracusotLyKXiMgyZ7sfFpGHy6jvMhH5j7Pd9pUwf4SIrHE+/xtFZFR57xfqaEIAVgAjjTHNgc5AAPBnZ14AsB+4FGgO/BZYJCIdayiWJsBPgNZAHHAF8D9eZWYbY0KcRw+vee8Dh4BooC3wVAXWeQz4J/B4KfP/CIwAhgPNgNuBnArUi4jEA4EVKVuNDgCTgTDsdvwIWFDLMZTkDuA4MLX4S8wlBzz2nxBjzBsXU4mIBAGLgbeBlsAbwGJnerGFXuvaU061LbD/rx5AOLDGWUfxOq8BfoX9XMRgP69/dGaHAGuBwdj//RvAv0UkxFm2D/ACdv8NB7KBZ8uIJR9YBNxTyvwD2O+JV8t5TxUtvxy4Dfv5rYhSy4tIa+Bz7PttBXQFviyjrjNOXL8ooa4w4GPgSez/5wngYxFpWW6ExphafQD7gF8DW7EftteAYOwXwSfACewX3reAXwXqCwHeBD4to8xGYFI5MV3pPG8MvO7EttXZ4GmVeH8/Az72eL0UuLeUslc76/a/yG15L7DUa1pL4DTQ5SLqaw7sAIYBBggoo2wjbPJKBQ4DzwONnXljgTTgN8BR5z3GVzCGAGAWkF1OuRHYL5OTzt8RXtv8MeyX0ynsF1SYMy/VeW+nncfwUuoXYDfwoPP+JnvN/wVwEPulcbdTZ1dn3vXAd8669wN/8Fiuo1P2LmfeceABYIizn54A5niUH1vW/gd0AN4DMoC9wI/LKHs1kA6Ix7RUYJzz/A/A2xezL3rUF+a8v1bO63nAXz3mXwEcKmP5U8Bg5/lfgXke87oAeUBoOTF0BUwZ8/8MvF6J91RmeWdfH1uJ+i4o77zXty5ie18J7POadgOwxWvaDuCe8upzq4UQD1yD/Qd3xx7F/xy7odpgjwZ+g92xSiQio0TkJJAFTMIeMZdULtxZx5YKxvZ7J64uToyVbZ6PKWFdjznN2BVeTcVhwHbgDRHJFJG1InJpJdfnrR9QAEx2muk7RGRWBZf9K/AcFTvieRy7XQdiP4ARwO885rfDJvkI7DZ80bsrwZuInMC2ZP7lxFJauTDg38Az2KOpv2OPLFt5FLsD+0XdHrs9nnGmj3H+tjD2CHhVKasZBURiWyqL8NgPRGQcthV4FdAN+6H0dMZZfwtscnhQRCZ4lYlzlp2K3XcfcerpA9zitR+0dboQ9orIP0SkqROHH/ZIMBm7na8AfuIclZekD7DRON8Qjo3O9GI3Ol0/W0TkwVLqKcsY7Bd+psc6kz3mJwPhXv8rnPczEAgCdpW0rDFmNzYhdL+IuHzdMOCY2K7gIyLysYhEV6E+KeF133KXqsrRwEUeQewDHvB4fR32SOxR7JFc10rWF4E9sulewrxA4CvghQrEVNxC2INzxOS8nkkFWwjYL6A0oLXHtDggFHtEPQObwLo4817EJr17nFinYY8QW1dwfSW1EKY7db6Cbe30xx49XlVOXbHABuwRekfKaCE4O9cZPFoh2O6pvc7zsdgv4aYe8xcB/68C76kp8BBwfRllbgfWeE1bBdzpPF8KPO4xrzf2i8S/vPfmsczLwIce7y0faOu8ftWr/u54tBBKqOufwD+c58Xrj/CYnwlM9Xj9HvAT53k7J34/oBOwrHh/dvatVK91/Rp4rZQ4/h+wwGtaAk4LxllPB2c7jcC2gG6txGcxEtsCudVj2m7O/zwFOu+/o9eyzYBNwK89pn2Nx3eFMy2dco7GqZsthB3Yz/4QbI/JM8CKCtRVUguhlVPXrc72ngEUUc73oDHutRD2ezxPwe6ET2KPDL4UkT0i8iuwfdoeA1yfeVdkjEnH9r2d1+fsHD29hf0imO0x/TOP+uJLiK1DCfEVL1tqLM4R4GPAtcaYox7xJRpjsowxucb2/a7AJkGAs9h/5ivGmHxjzAJn3SNLiKuizjp/HzXGnDXGbMRum+tKW8DZVs8CDxtjCkqY/xuP9/08thXXBFgnIiecI/vPnenFjhtjzni8TgE6iEi0R12nvdflLPM88KYz6FhS+Q54/F886o/weO39PwzEtlhKev9bPNYxWkQaA1OwX5YY24pIxSbb4vWXuI849cU5A34ZTiv2gRLWfdjj+dkSXoc46z5kjNlqjCkyxuwFfoltEYPtk+9Q/D9w/g+/wbawkfMHh6OxXWTNvOJohj1IwVnPAWNMoTFmJfA0dmynXCLSBtvn/awxZr7HLO91Fj/P8li2Mbals9oY81gZy/4Qb3nfC5VVge+FytRV5j5eirPAB8aYtcaYHJxxQBFpXsLnr0zGts7GY7uvDwPjsAfG5Z4tWStnkZQgyuN5NHbQLAvbbfRzEekLfCMia40xCTgfzDIEYLt4ABARwR4hhwPXGWPyi+cZY8o74+igE19xt88PzbbSYnG6EF7CHtVuKqd+w7nm3EbgxhLmV8XGEuopr85m2BbCQrvp8Hemp4nIFGPMX/HownESyFmgj5OQS9JSRJp6JIVoYLMxJhXny64MftiEE2GM+a6E8gewX4aeorFJqZj3PpaPHc+I9F6ZMcazywQRmY7dJs+KyL+cyS2wR1r/5Nw+4lm/p3nAHOzBQY6I/JNSktFFMJw7GWQ/tlXWrcSCxpy33URkC/bzJcY5lMS2IOeWsS7vrocLOIOVXwIfGWP+4jV7CzAA20LEeX7Y+dJC7GD9h9gvq/tLWbZ4PZ2xLe0dxph1lP+9UGEV+F6oTF0V2ce9baSUz6z356+CMfwX29pA7Bl1e4C/VWTBWn1gu2c2YT+YYdiR979iB0K6YnfAKOyH7rJS6ogHop3nMcB/gfc95j8PrAZCKhFTcZfR/zn1tXRi3EjZg3qXY5v8Y0qY1wI7DhGMTVrx2K6W7s78MOyg4gzsl/Bk7IB6mV1GTtlg7JHnMud5oMf8ZdizFRoBvYAjwBVl1CfYronixxCcbg0gqJRlnsZ+yIu7USKAa5znY7FdRk9h+4RHO++7Zyl1XQUMct5XM2xz+QAQXEr54ibxdGe7TsWjqw3bZZSG7QJpAryDMzjpvC6khC5Gj/q/wB5QeG6Twdhmdz/gWuw4S3H9b3P+oPIRYIbzfKjz+m3ndUe8uqzw6kJw6vut8/wy7D5e/Ln4D06XkLO91gP/i+0e9Mf2Ew8p5X0FYVszDzv7xmzndZAzfzx2vxcn7vTi91HGtmqGHbyfU8r8cR7bqgXwDU53G7bV9jE2IVzQhYcdQzjl7D9Nne2yoIxYBPtZ6O1s42Cgkcf8AGfaY9jeg+CS1lvR8s42DHb+f1c7z6WM+kotj/0eOY4dkwsE/gF8W0Zdfs7y1zr/w2A8PqvYz1Og8//5JxXofjLGuH6W0QnsqWZNgJ868844G6zU/mbgL06Z4rIvcu6shhhnZ8jh3JkkpynjLBfOTwhNsGctnaACZxlhP6AFXuv6zJnXBnsGTJZT32q8+vKdnX2Ts1wSMLoC2/BO5z16Pl73mB+BPVo+jT0yuL+S/6OOlH+WUTA2ke/Bfmi34ZzhwrmzjB7BHpWnAreXUdcU4Hsn3gzsgHH/cmIcBazDnmW0DhjlMW8p559l9DHnj+s86qznBDDMq94I5//Zr4R1fgo85Tz/FfaLrqSzjCZjP6RZ2DPn5nDxCeFn2C/mbGyL4Bk8zrLBdl/Nd2I57uxjV5ax3QY52+ssNpkM8pg3H3twc9r5f5R6xpLHMjOc93OG8z8D0R5lirsuTmHPKmzkTL/UWTbba9nRHstOd/afM3icLVbOfuv52Ocx/w8lzP9DGfWVWR77veE9v2M53zOllsee0Zbu/B8/BqLKqGtsCXUt9fpfnnQeC3EO3Mp7FGcnpaqNcybV28aYC7pnamn9S531v+zG+pWqq+rqD9OUUkpVM00IPsrrDBHPx+gq1PlZKXX+pjpjV/WL1xk9no+K/rZH1RHaZaSUUgrQFoJSSimHW79DKFPr1q1Nx44d3Q5DKaXqjHXr1h01xrQpv2TpfDIhdOzYkaSkJLfDUEqpOkNEvH+9X2naZaSUUgrQhKCUUsqhCUEppRTgo2MISimVn59PWloaOTkVutlfgxEcHExkZCSBgdV/Y0NNCEopn5SWlkZoaCgdO3bEuQpvg2eMITMzk7S0NDp16lTt9WuXkVLKJ+Xk5NCqVStNBh5EhFatWtVYq0kTglLKZ2kyuFBNbpNyE4KIRDl3f9rq3FnqYWd6mIgsEZGdzt+WpSw/wymzU0RmVPcb8PSvr3eyOf1kTa5CKaXqrYq0EAqAnxtjemNvBD1LRHpjrwf/tbF3a/raeX0esTdD/z323q9Dgd+Xljiq6kR2HvPWpDLl+VV8tulgTaxCKaXqtXITgjHmoDFmvfM8C3sjlAjs3ZXecIq9AUwoYfFrgCXGmGPGmOPAEuwdlKpdiyZBLJ49kp7tQ3kwYT1Pf7UTvXCfUqoqQkIqeyfMynn99dc5cOBAja6jMio1hiAiHbF3XEoEwo0xxYfih3Bu7O0lgvNvRp7G+TdC96x7pogkiUhSRkZGZcL6QdvQYObfN4ybL4ngH1/tYPb87zibV3hRdSmlVE0rKyEUFtb+d1eFTzsVkRDgPeAnxphTngMbxhgjIlU6HDfGvIi9FSaxsbEXXVdwoD9/mzKAHuGhPP7596RmZvPSHbG0ax5clfCUUi7648db2HrgVLXW2btDM35/Y58KlTXG8Mtf/pLPPvsMEeG3v/0tU6dO5eDBg0ydOpVTp05RUFDAc889x4gRI7jnnntISkpCRLj77rv56U9/ekGd7777LklJScTHx9O4cWNWrVpFr169mDp1KkuWLOGXv/wl06ZNq9b3XJ4KJQQRCcQmgwRjzPvO5MMi0t4Yc1BE2mNvJO4tHXvvz2KR2Pvd1igR4f5Lu9C1bQg/nv8dN81Zzot3xDIwqkVNr1opVQ+9//77bNiwgeTkZI4ePcqQIUMYM2YM8+bN45prruGRRx6hsLCQ7OxsNmzYQHp6Ops3bwbgxIkTJdY5efJk5syZw1NPPUVsbOwP01u1asX69etr421doNyEILYp8AqwzRjzd49ZH2FvsP2483dxCYt/AfzVYyD5auDXVYq4Eq7oFc77D43k3jfXcssLq3hycn/GDyyxx0op5cMqeiRfU5YvX86tt96Kv78/4eHhXHrppaxdu5YhQ4Zw9913k5+fz4QJExg4cCCdO3dmz549/OhHP+L666/n6quvrtS6pk6dWkPvonwVGUMYCdwOXC4iG5zHddhEcJWI7ASudF4jIrEi8jKAMeYY8CdgrfN41JlWa3q0C2XxrFEMjGrBwws28MTn31NUpIPNSqmqGzNmDMuWLSMiIoI777yTN998k5YtW5KcnMzYsWN5/vnnuffeeytVZ9OmTWso2vKV20IwxiwHSvslxBUllE8C7vV4/Srw6sUGWB3Cmgbx9j1x/G7xZp5dupudR07zj6kDCWmkV+5QSpVv9OjRvPDCC8yYMYNjx46xbNkynnzySVJSUoiMjOS+++4jNzeX9evXc9111xEUFMSkSZPo0aMHt912W6n1hoaGkpWVVYvvpGwN5hsxKMCPx27uR492ofzpk61Mfm4lL90RS1RYE7dDU0r5uIkTJ7Jq1SoGDBiAiPDEE0/Qrl073njjDZ588kkCAwMJCQnhzTffJD09nbvuuouioiIAHnvssVLrvfPOO3nggQd+GFR2m/jiufqxsbGmJu+YtmxHBrPmrSfQ348Xbh/MkI5hNbYupdTF2bZtG7169XI7DJ9U0rYRkXXGmNhSFqmQBnktozHd2/DhrJG0aBzI9JdWs2jt/vIXUkqpeq5BJgSALm1C+OChkQzr3IpfvreRP32ylYLCIrfDUkrVQ7NmzWLgwIHnPV577TW3w7pAgxlDKEnzJoG8ducQ/vzvbbyyfC+7jpzmX9MH0Sy4+m88oZRquObOnet2CBXSYFsIxQL8/fjDTX3468R+rNh1lIlzV7D36Bm3w1JKqVrX4BNCselx0bx1TxzHzuQxYe4KVuw66nZISilVqzQheBjepRWLZ40ivFkj7nh1DW+t2ud2SEopVWs0IXiJbtWE9x4cwdjubfh/i7fw2w83ka+DzUqpBkATQglCgwN58Y5Y7r+0M2+vTuWOV9Zw/Eye22EppWpZTd8PwddoQiiFv5/w62t78bcpA1iXcpwJz65g1xHf+Ym5UkpVtwZ92mlFTBocScfWTbn/rSQmzl3JM9MHcVmPtm6HpVTD8tmv4NCm6q2zXT+49vEKFa2J+yEA7Nq1iwceeICMjAz8/f155513eOSRR7j99tu5/vrrAXt5ixtuuIHJkydX21svjbYQKmBwTEsWzx5FVFgT7nl9LS9/u0dvz6lUA+J5P4SvvvqKX/ziFxw8ePCH+yEUzxs4cOB590PYtGkTd911V6n1xsfHM2vWLJKTk1m5ciXt27dn6tSpLFq0CIC8vDy+/vrrH5JDTdMWQgVFtGjMuw8O5+eLkvnzv7ex/VAWf57Yl0YB/m6HplT9V8Ej+ZpSE/dDyMrKIj09nYkTJwIQHGzv6njttdfy8MMPk5uby+eff86YMWNo3LhxrbxPbSFUQpOgAOZOv4QfX9GNd9alEf9SIkdP57odllLKJTVxP4Tg4GDGjh3LF198wcKFC2v1hjmaECrJz0/42VXd+detg9iUfpLxc1aw7WD13utVKeVbRo8ezcKFCyksLCQjI4Nly5YxdOhQUlJSCA8P57777uPee+9l/fr1HD16lKKiIiZNmsSf//znUm+HGRoaSmRkJB9++CEAubm5ZGdnA/auaa+99hrffvst48aNq623qQnhYt04oAPvPDCcgqIiJj23ki+2HHI7JKVUDZk4cSL9+/dnwIABXH755T/cD2Hp0qUMGDCAQYMGsXDhQh5++GHS09MZO3YsAwcO5LbbbivzfghvvfUWzzzzDP3792fEiBEcOmS/R66++mr++9//cuWVVxIUFFRbb7Nh3g+hOh0+lcPMN5NITjvJL67pwUNju2BvQ62Uqgq9H0LpXLsfgoi8KiJHRGSzx7SFHvdX3iciG0pZdp+IbHLK1Y1v+EoKbxbMwvuHM35gB578YjsPL9hATn6h22EppVSlVeQso9eBOcCbxROMMT+McojI34CTZSx/mTGmXl8pLjjQn39OHUj38FCe/GI7KZlnePGOWMKbBbsdmlLKB8yaNYsVK1acN+3hhx8u85RUN5SbEIwxy0SkY0nzxPaN3AJcXs1x1TkiwqzLutKtbQg/WbiBm+Ys56U7Yukf2cLt0JSqs4wx9aILtjrvh1CT3fxVHVQeDRw2xuwsZb4BvhSRdSIys6yKRGSmiCSJSFJGRkYVw3LP1X3a8d6DIwjw82PK86v4OPmA2yEpVScFBweTmZmpPwL1YIwhMzPzh98sVLcKDSo7LYRPjDF9vaY/B+wyxvytlOUijDHpItIWWAL8yBizrLz11aVB5dIcPZ3Lg2+vY+2+4/z48q785Mru+PnV/SMdpWpLfn4+aWlp5OTkuB2KTwkODiYyMpLAwPPv7Fgdg8oX/UtlEQkAbgYGl1bGGJPu/D0iIh8AQ4FyE0J90DqkEW/fG8dvP9jMM9/sYsfh0/x96gCaBOmPw5WqiMDAQDp16uR2GA1KVbqMrgS+N8aklTRTRJqKSGjxc+BqYHNJZeurRgH+PDG5P7+9vhdfbj3EpOdWkX7irNthKaVUiSpy2ul8YBXQQ0TSROQeZ9Y0YL5X2Q4i8qnzMhxYLiLJwBrg38aYz6sv9LpBRLh3dGdeuXMIaceyGT9nOetSjrkdllJKXUB/mFaLdh3J4t43kjhwIoe/3tyPyYMj3Q5JKVVP1MoP01T16do2lA9njSS2Y0v+551kHvt0G4VFvpeQlVINkyaEWtaiSRBv3D2U24fF8MKyPdz3ZhJZOfluh6WUUpoQ3BDo78efJvTlT+P78N8dGdz87EpSM7PdDksp1cBpQnDR7cM78tbdQzmSlctNc5ezanem2yEppRowTQguG9G1NYtnjaRV0yBufyWReYmpboeklGqgNCH4gI6tm/LBrJGM6taa33ywiT98tIWCwiK3w1JKNTCaEHxEs+BAXpkxhPtGd+L1lfu487W1nMzWwWalVO3RhOBD/P2ER67vzROT+5O4N5MJz65gd8Zpt8NSSjUQmhB80C2xUcy7bxinzuYzYe4Klu2ou1d/VUrVHZoQfNSQjmF8OGskES0ac+dra3h1+V69DLBSqkZpQvBhUWFNeO/BEVzRK5xHP9nKr9/fRF6BDjYrpWqGJgQf17RRAC/cNphZl3Vhwdr93PZKIsfO5LkdllKqHtKEUAf4+Qm/uKYnT08byIb9J7hpznK2H8pyOyylVD2jCaEOGT8wgkX3DyevoIibn13BV1sPux2SUqoe0YRQxwyMasFHs0fRuU0I972VxHNLd+tgs1KqWmhCqIPaNQ9m0f3Dub5fe/7v8+/52aJkcvIL3Q5LKVXH6Q1+66jGQf7869ZBdA8P5e9LdrD36BlevGMwbUOD3Q5NKVVHaQuhDhMRfnxFN56Lv4Tth7IYP2cFm9NPuh2WUqqOqsg9lV8VkSMistlj2h9EJF1ENjiP60pZdpyIbBeRXSLyq+oMXJ1zbb/2vPvgcASY/PxKPt100O2QlFJ1UEVaCK8D40qY/g9jzEDn8an3TBHxB+YC1wK9gVtFpHdVglWl69OhOYtnj6J3+2Y8lLCep7/aqYPNSqlKKTchGGOWAccuou6hwC5jzB5jTB6wABh/EfWoCmoT2oj5M4dx8yUR/OOrHcye/x1n83SwWSlVMVUZQ5gtIhudLqWWJcyPAPZ7vE5zppVIRGaKSJKIJGVk6MXcLlajAH/+NmUAv7muJ59uOsiUF1Zy8ORZt8NSStUBF5sQngO6AAOBg8DfqhqIMeZFY0ysMSa2TZs2Va2uQRMRZo7pwst3xLLvaDY3zVnBd6nH3Q5LKeXjLiohGGMOG2MKjTFFwEvY7iFv6UCUx+tIZ5qqJVf0Cuf9h0bQONCfqS+u5oPv0twOSSnlwy4qIYhIe4+XE4HNJRRbC3QTkU4iEgRMAz66mPWpi9c9PJQPZ41kUFQLfrowmf/7/HuKinSwWSl1oYqcdjofWAX0EJE0EbkHeEJENonIRuAy4KdO2Q4i8imAMaYAmA18AWwDFhljttTQ+1BlCGsaxFv3xHHr0GieW7qbmW+t43RugdthKaV8jPjiqYmxsbEmKSnJ7TDqHWMMb65K4dFPttKtbQgv3RFLVFgTt8NSSlUDEVlnjImtSh36S+UGRESYMaIjr981hAMnzjJ+7goS92S6HZZSykdoQmiARndrw4ezRtKicSC3vZLIwrWpboeklPIBmhAaqM5tQvjgoZEM69yK/31vE49+vJWCQr09p1INmSaEBqx5k0Beu3MId43syKsr9nL3G0mcPJvvdlhKKZdoQmjgAvz9+P2NfXjs5n6s3HWUic+uYO/RM26HpZRygSYEBcCtQ6N5+944jp/JY8LcFSzfedTtkJRStUwTgvrBsM6t+Gj2KMKbNWLGa2t4c9U+vWKqUg2IJgR1nqiwJrz34AjGdm/D7xZv4bcfbiZfB5uVahA0IagLhAYH8uIdsTxwaRcSElO5/ZVEjp/JczsspVQN04SgSuTvJ/zq2p78/ZYBrE85wfi5K9h5OMvtsJRSNUgTgirTzZdEsuD+YWTnFTLx2ZX85/sjboeklKohmhBUuS6JbslHs0cS06oJd7+xlpeW7dHBZqXqIU0IqkI6tGjMOw8MZ1yfdvzl02384t2N5Bbo7TmVqk80IagKaxIUwNzpl/DwFd14d10a019KJCMr1+2wlFLVRBOCqhQ/P+GnV3VnzvRBbDlwkglzV7D1wCm3w1JKVQNNCOqi3NC/A+/cP4LCIsOk51by+eZDboeklKoiTQjqovWLbM5Hs0fSo10oD7y9jjnf7NTBZqXqME0IqkraNgtmwcxhTBjYgae+3MGPF2wgJ18Hm5WqiypyT+VXReSIiGz2mPakiHwvIhtF5AMRaVHKsvucey9vEBG9J2Y9FRzozz+mDuSX43rwycYD3PLCKg6fynE7LKVUJVWkhfA6MM5r2hKgrzGmP7AD+HUZy19mjBlY1Xt9Kt8mIjw0tisv3DaYXUdOc9Oc5STvP+F2WEqpSig3IRhjlgHHvKZ9aYwpcF6uBiJrIDZVB13dpx3vPTiCAD8/bnlhFYs3pLsdklKqgqpjDOFu4LNS5hngSxFZJyIzy6pERGaKSJKIJGVkZFRDWMotvdo346PZI+kf2ZyHF2zgb19up6hIB5uV8nVVSggi8ghQACSUUmSUMeYS4FpgloiMKa0uY8yLxphYY0xsmzZtqhKW8gGtQhqRcO8wpsZG8a9vdvFgwjrO5BaUv6BSyjUXnRBE5E7gBiDelHKuoTEm3fl7BPgAGHqx61N1T1CAH49P6sfvbujNkq2Hmfz8KtKOZ7sdllKqFBeVEERkHPBL4CZjTImfcBFpKiKhxc+Bq4HNJZVV9ZeIcPeoTrx211DSjmczYe4K1qUcK39BpVStq8hpp/OBVUAPEUkTkXuAOUAosMQ5pfR5p2wHEfnUWTQcWC4iycAa4N/GmM9r5F0on3dp9zZ88NBIQhoFcOuLibyTtN/tkJRSXsQXf1kaGxtrkpL0Zwv10YnsPGbNW8+KXZncN7oTv7q2F/5+4nZYStV5IrKuqqf36y+VVa1q0SSI1+8ayh3DY3jp273c+8ZaTuXkux2WUgpNCMoFgf5+PDq+L3+e0Jdvdx7l5mdXkpJ5xu2wlGrwNCEo19w2LIY37xnK0dO5jJ+7gpW7j7odklINmiYE5aoRXVqzeNZIWoc04o5X1pCQmOJ2SEo1WJoQlOtiWjXl/YdGMLpbax75YDO/X7yZgsIit8NSqsHRhKB8QrPgQF6eMYT7RnfijVUpzHhtDSey89wOS6kGRROC8hn+fsIj1/fmicn9WbP3GBPmrmDXkdNuh6VUg6EJQfmcW2KjmH/fMLJyCpj47AqWbj/idkhKNQiaEJRPiu0YxuLZI4ls2YS7X1/LK8v36u05laphmhCUz4ps2YR3HxjOVb3D+dMnW/n1+5vIK9DBZqVqiiYE5dOaNgrgufjB/OjyrixYu5/bXk4k83Su22EpVS9pQlA+z89P+PnVPXh62kCS004wfu4Kvj90yu2wlKp3NCGoOmP8wAgW3T+cvIIiJj27kiVbD7sdklL1iiYEVacMiGrBR7NH0aVtCDPfSuLZpbt0sFmpaqIJQdU57ZoHs+j+4dzQvwNPfL6dny7cQE5+odthKVXnBbgdgFIXIzjQn2emDaRHeAhPfbmDfZnZvHj7YNo2C3Y7NKXqLG0hqDpLRJh9eTeev20w2w9lMX7uCjann3Q7LKXqLE0Iqs4b17cd7z44HAEmP7+Sf2886HZIStVJFUoIIvKqiBwRkc0e08JEZImI7HT+tixl2RlOmZ0iMqO6AlfKU58OzVk8exR9OjRn1rz1/GPJDoqKdLBZqcqoaAvhdWCc17RfAV8bY7oBXzuvzyMiYcDvgThgKPD70hKHUlXVJrQR8+6LY9IlkTz99U5mz19Pdl6B22EpVWdUKCEYY5YBx7wmjwfecJ6/AUwoYdFrgCXGmGPGmOPAEi5MLEpVm0YB/jw1pT+PXNeLzzYfYsrzqzhw4qzbYSlVJ1RlDCHcGFPcWXsICC+hTASw3+N1mjPtAiIyU0SSRCQpIyOjCmGphk5EuG9MZ16dMYSUzGxumrOC9anH3Q5LKZ9XLYPKxv4yqEodtsaYF40xscaY2DZt2lRHWKqBu6xnWz54aARNgvyZ9uJq3l+f5nZISvm0qiSEwyLSHsD5W9JF69OBKI/Xkc40pWpFt/BQFs8aySXRLfjZomQe/+x7HWxWqhRVSQgfAcVnDc0AFpdQ5gvgahFp6QwmX+1MU6rWtGwaxFv3xDE9Lprn/7ubmW8lcTpXB5uV8lbR007nA6uAHiKSJiL3AI8DV4nITuBK5zUiEisiLwMYY44BfwLWOo9HnWlK1apAfz/+MqEvj47vw3+2ZzDp2ZXsP5btdlhK+RTxxQuDxcbGmqSkJLfDUPXU8p1HeShhHf5+wvO3DSaucyu3Q1KqykRknTEmtip16C+VVYMzqltrPpw1kpZNg4h/OZEFa1LdDkkpn6AJQTVInduE8MFDIxnRtTW/en8Tf/x4CwWFentO1bBpQlANVvPGgbw6I5a7R3bitRX7uOv1tZw8m+92WEq5pn4lhH3LIUdvragqLsDfj9/d2JvHb+7H6j2ZTHx2BXsyTrsdllKuqD8JIe8MJNwCT3WDd++GHV9CoZ5aqCpm2tBo3r4njhPZ+UyYu4Jvd+qv5VXDU38SQmATmPERDLoNdn8D86bA33vC57+GAxvAB8+mUr4lrnMrFs8aSfvmjbnztbW8sXKf3p5TNSj187TTgjzY+SVsXADbP4eifGjTCwZMhX63QPMSL6ekFACncwv4yYLv+GrbEabHRfPHm/oQ6F9/jp1U/VQdp53Wz4TgKfsYbPkANi6E/YmAQKcxMOBW6HUjNAqpnvWoeqWoyPDkl9t5buluhnUO47n4wbRsGuR2WEqVShNCZWXuho2LIHk+nEix3Uy9boT+U6HzWPDzr/51qjrtg+/S+N/3NtGuWTAvz4ile3io2yEpVSJNCBfLGNtaSJ5vWw85JyGkHfSfAv2nQbu+NbduVeesTz3OzDfXkZNfyB9v6sONAzoQFKBdSMq3aEKoDvk5sONz26W080soKoDwfs54wxQIbVc7cSifduDEWe5/ax2b0k/SOiSIKbFRTB8aTVRYE7dDUwrQhFD9zhyFze/bwej0dSB+0PkyO97Q83oI0g9/Q1ZUZFi2M4OExFS+3nYYA4zp1ob4uGgu79mWAB14Vi7ShFCTMnbYVsPGhXByPwSFQO/xdryh42jw0w9/Q3bw5FkWrNnPgrWpHD6VS/vmwUwbEs3UIVG0ax7sdniqAdKEUBuKiiB1pTPesBjysqBZBPS/xY43tO3pdoTKRQWFRXz9/RESElNZtiMDfz/hyl5tiY+LYVTX1vj5idshqgZCE0Jty8uG7Z/aVsOur8EUQvuBMGAa9J0MIXrrz4YsJfMM89ak8k5SGsfO5BEd1oTpcdFMGRxJq5BGboen6jlNCG46fQQ2vWvHGw4mg/hD1yttcuhxLQQ2djtC5ZLcgkI+33yIhMRU1uw9RpC/H+P6tiM+LpqhncIQ0VaDqn6aEHzFkW2QvMD+xiHrADRqBn0m2C6l6OE63tCA7TycRUJiKu+tTyMrp4BubUOIj4tm4iWRNG8c6HZ4qh7RhOBrigph37c2OWz9CPLPQPNoewpr/2nQuqvbESqXnM0r5OONB0hITCV5/wmCA/24aUAH4uNi6B/ZXFsNqspcTQgi0gNY6DGpM/A7Y8w/PcqMBRYDe51J7xtjHi2v7jqbEDzlnYHv/20Ho/csBVMEEbHOeMMkaBLmdoTKJZvTT5KQmMLiDQfIziukb0Qz4uNiuGlAB5o2CnA7PFVH+UwLQUT8gXQgzhiT4jF9LPA/xpgbKlNfvUgInk4dhE3v2JbDkS3gFwjdrrbJofs1EKADjg3RqZx8Fn+XTkJiKt8fyiKkUQATB0UQPyyanu2auR2eqmN8KSFcDfzeGDPSa/pYNCGc79Ammxg2vQOnD0NwC+h7s+1SihoK2nXQ4BhjWJ96nITVqXyy6SB5BUUMjmlJfFw01/VrT3CgXmNLlc+XEsKrwHpjzByv6WOB94A04AA2OWwppY6ZwEyA6OjowSkpKSUVqz8KC2DvUkheCNs+hoKz0LKTbTX0vwXCOrsdoXLB8TN5vLc+jYTEVPYePUOLJoFMviSS6XHRdG6jV+ZVpfOJhCAiQdgv+z7GmMNe85oBRcaY0yJyHfC0MaZbeXXW6xZCSXKzbFJIng97vwUMRA2zg9F9JkLjlm5HqGqZMYZVuzN5OzGFL7ccpqDIMLJrK+LjYriqd7jen0FdwFcSwnhgljHm6gqU3QfEGmOOllWuwSUETyfT7OmrGxdCxvfgHwTdx9nrKXW9EgL0mvwNzZFTOSxK2s/8NftJP3GWNqGNmBobxbShUUS21OtrKctXEsIC4AtjzGslzGsHHDbGGBEZCrwLxJhyVtqgE0IxY+DgBtultOkdyD4KjcPsGUoDboWIS3S8oYEpLDL8d8cRElan8s32IwBc1qMt8XHRjO3RFn+9TEaD5npCEJGmQCrQ2Rhz0pn2AIAx5nkRmQ08CBQAZ4GfGWNWllevJgQvhfn2PtHJC+yprIW50KqrM94wFVpEux2hqmVpx7NZuHY/C9buJyMrl4gWjZk2JIqpQ6Jo20wvrtcQuZ4QaoomhDLknISti21ySFlhp8WMsuMNvcdDcHN341O1Kr+wiK+2HiYhMZXlu44S4Cdc1Tuc24bFMLxzK724XgOiCaGhO57ijDcsgMxdEBAMPa6zXUpdLgd//ZFTQ7L36BnmJabwzro0TmTn06l1U6YPjWby4Ei9H3QDoAlBWcbYG/okL4DN78LZ49C0jb0C64Bp0H6Ajjc0IDn5hXy2+SAJq1NJSjlOUIAf1/drT3xcNINjWuplMuopTQjqQgV5sGuJTQ47PofCPGjT0yaGfrdA8wi3I1S16PtDp5iXmMr769M5nVtAj/BQ4odFM2FQBM2C9eJ69YkmBFW27GOw9UObHPYnAgKdxtjk0OtGaBTqdoSqlpzJLeDj5AO8nZjC5vRTNA70Z/xAe3G9fpE67lQfaEJQFZe5+9x4w/F9ENgEet5gk0PnseCnl0doKDamnSBhdSqLk9PJyS9iQGRz4uNiuGFAe5oE6bhTXaUJQVWeMba1kLwAtrxvz1oKaQf9JtvB6HZ93Y5Q1ZKTZ/P58Lt03l6dws4jpwkNDmCSc5mM7uHaeqxrNCGoqsnPgZ1f2B+/7fwCigogvK8z3jAFQtu5HaGqBcYY1u47TkJiCp9tOkReYRFDO4YRPyyacX3b0ShAW491gSYEVX3OZNoWQ/J8e8aS+EHny2xy6Hk9BDV1O0JVCzJP5/LuujTmrUklJTObsKZBTImNZPrQaGJa6T7gyzQhqJpxdOe5W4KeTIWgEOh1k00OHUfrLUEbgKIiw4rdR0lYncqSbYcpLDKM7taa+LgYrujVVi+u54M0IaiaVVQEqSudW4IuhtxT0CzCdicNuBXa9nQ7QlULDp/KYeHa/cxfk8rBkzmEN2vE1CHRTBsSRYcWjd0OTzk0Iajak38Wtn9qxxt2fQWm0P7gbcCt9gdwIW3cjlDVsILCIv6zPYOExBT+uyMDAS7vGU78sGjGdGujF9dzmSYE5Y7TR2Dze3a84WAyiL+9NPeAqfbSGYF61Fjf7T+Wzfw1qSxK2s/R03lEtmzMrUOjuSU2ijahektYN2hCUO47su3cLUFPpUOjZvYiewNuhejhOt5Qz+UVFPHl1kMkrE5l1Z5MAv2Fa/q0Iz4uhmGdw/QyGbVIE4LyHUWFsO9b55agH0HeaWgebVsN/adB665uR6hq2K4jp5m/JpV316Vx8mw+nds0JT4uhkmXRNCiiV5cr6ZpQlC+Ke+MvW9D8gLY8x8wRRAx2LYa+twMTVu5HaGqQTn5hXyy8SAJiSl8l3qCRgF+3NC/A/HDohkU1UJbDTVEE4LyfVmHbHdS8gI4vBn8AqDbNbbl0H0cBGh/c3225cBJ5iWm8uF36ZzJK6RX+2bEx9mL64U00stkVCdNCKpuObTZXktp4ztw+hAEt4A+E23LIWqoXqK7HjudW8DiDem8vTqVbQdP0TTIn/GDIrgtLobeHZq5HV69oAlB1U1FhbBnqXNL0E8gPxtadnJuCXoLhHV2O0JVQ4wxbNh/goTEVD5OPkBuQRGDolvYi+v1b09woF4m42L5REIQkX1AFlAIFHgHJLbD8GngOiAbuNMYs76sOjUhNCC5WbDtY5sc9i4DDEQNs11KfSZC45ZuR6hqyMnsfN5bn0ZCYgq7M87QLDiAyYOjmB4XTde2IW6HV+f4UkKINcYcLWX+dcCPsAkhDnjaGBNXVp2aEBqok+mwaZFNDhnfg3+QHWcYMA26XgUBeqZKfWSMIXHvMd5encIXWw6RX2gY1jmM+LgYrunTjqAAPXW5IupKQngBWGqMme+83g6MNcYcLK1OTQgNnDH2B28bF9oB6TMZ0DgM+k6y4w0Rl+h4Qz2VkZXLO+v2My8xlbTjZ2kdEsSU2CimD40mKqyJ2+H5NF9JCHuB44ABXjDGvOg1/xPgcWPMcuf118D/GmOSvMrNBGYCREdHD05JSalSXKqeKMyH3f+xv4re/ikU5ECrrs54w1RoEe12hKoGFBUZlu3MICExla+3HcYAY7q14bZhMVzWow0BenG9C/hKQogwxqSLSFtgCfAjY8wyj/kVSgietIWgSpRz0l5kL3khpCy302JG2fGG3uMhWG8FWR8dOHGWhWv3s2BtKodP5dK+eTDThkQzdUgU7ZoHux2ez/CJhHBeZSJ/AE4bY57ymKZdRqr6HU9xxhsWQuZOCAi211EaMA26XA7+egP5+qagsIivvz9CQmIqy3Zk4O8nXNmrLfFxMYzq2hq/Bn5xPdcTgog0BfyMMVnO8yXAo8aYzz3KXA/M5tyg8jPGmKFl1asJQVWYMZC+3v6+YdO7cPYYNG1jr8A6YJq9IquON9Q7KZlnmLcmlXeS0jh2Jo/osCZMj4tmyuBIWoU0zB87+kJC6Ax84LwMAOYZY/4iIg8AGGOed047nQOMw552eldZ3UWgCUFdpII8e2nu5Pmw43MozIM2PZ1bgt4CzSPcjlBVs9yCQj7ffIiExFTW7D1GkL8f1/azF9cb0rFlg7pMhusJoaZoQlBVdvY4bPnAdintXw0IdBpjk0OvG6GR3kS+vtl5OIuExFTeW59GVk4B3dqGEB8XzcRLImneuP53IWpCUKoiju2xtwNNXgDH90JgE+h5gx2M7nwZ+OmvY+uTs3mFfLzxAAmJqSTvP0FwoB83DehAfFwM/SOb19tWgyYEpSrDGNi/xo43bH7PnrUU0g76Tba/b2jX1+0IVTXbnH6ShMQUFm84QHZeIX0jmhEfF8NNAzrQtJ5dXE8TglIXqyAXdnxhWw07v4SifAjv64w3TIHQdm5HqKrRqZx8Fn9nL663/XAWIY0CmDgogvhh0fRsVz8urqcJQanqkH3MuSXoAkhPAvGzXUkDpkHP6yGoqdsRqmpijGF96nESVqfyyaaD5BUUERvTkvhh0Vzbt25fXE8TglLV7egu5xLdC+FEKgSFQK+b7HhDx9E63lCPHD+T51xcL5W9R8/QokkgUwZHMj0uhk6t695BgCYEpWpKURGkrrLJYcuHkHsKmkXYH7216gJhXezflp0gSK+xU5cZY1i1O5O3E1P4csthCooMI7u2Ij4uhqt6hxNYRy6ToQlBqdqQfxa2f2bPVEpPshfb8xTawUkSnc/9DesCYZ0gsLE7MauLcuRUDouS9jN/zX7ST5ylTWgjpsZGMW1oFJEtfTvxa0JQyg05J+2prMf2QOYeOLYbMnfb19leF/1tFmkTQ3GrojhptOwEgXodHl9VWGT4744jJKxO5ZvtRwC4rEdbbhsWzaXd2+Lvg5fJ0ISglK85e+Jcsji2x0kUxcki06OgQHMnWRR3PxUnjJYdNVn4kLTj2c7F9faTkZVLRIvG3Do0iltio2jbzHf+T5oQlKpLzh73aFV4tix223k/EGgeBa06n+t+Kk4YLWMgoGFeq8dt+YVFfLX1MAmJqSzfdZQAP+HqPuHEx8UwvHMr1y+upwlBqfoi+xgc23t+91Px85wT58qJn9Oy8ByzcBJGixi9q1wt2Xv0DPMSU3hnXRonsvPp1Lop04dGM3lwJC2buvM/0ISgVEOQfezC7qfi5zknz5UTP6dl0eXChNEyRi8JXgNy8gv5bPNBElankpRynKAAP67v1574uGgGx9TuxfU0ISjVkBlzLll4dj8Vd0vleiYLf2gRdeF4Rasu9q5zmiyq7PtDp5iXmMr769M5nVtAz3ahxMdFM2FQBKHBNb99NSEopUpmjB3E9u5+Kh7szj11rqz426Tg2f0U5oxftIgB//p1zZ+adia3gI+TD/B2Ygqb00/RJMif8QPtxfX6RtTcXf00ISilKs8YOHP0wu6n4oSRd/pcWb8AmxTOG69wkkXzaE0W5diYdoKE1aksTk4nJ7+IAZHNiY+L4cYBHWgcVL2/eteEoJSqXsbYH96VNF6RuQfyz5wr6xdoxybOOxOquGURrZf58HDybD4fOJfJ2HnkNKHBAUy6JJLpcdF0D6+ee3NoQlBK1R5j4PSRkscrjpWULDqenySKWxjNIxtssjDGsHbfcRISU/hs0yHyCosY2jGM+GHRjOvbjkYBF79dNCEopXyDMZB1qOTximN7ID/7XFn/IJssfmhVePw4r1kk+NWNawdVVebpXN5dl8a8NamkZGYT1jSIKbGR/Oyq7heVGFxNCCISBbwJhAMGeNEY87RXmbHAYmCvM+l9Y8yj5dWtCUGpesQYyDpYwnjFXjut4Oy5sv6Nzm9ZeF4bqllEvUwWRUWGFbuPkrA6lbQT2Xw8e9RFna5aHQmhKiNCBcDPjTHrRSQUWCciS4wxW73KfWuMuaEK61FK1WUi0KyDfXQcdf68oiInWXiOVzh/d38DBTnnyvo38mhNdD7/1NnQDnU2Wfj5CaO7tWF0tzbkFxa5eovPi04IxpiDwEHneZaIbAMiAO+EoJRSJfPzg+YR9tFpzPnzioog64DXqbPO311fQWHuubIBwefGKjzHK8I6Q2j7OpMs3L7UdrWcMyYiHYFBQGIJs4eLSDJwAPgfY8yWUuqYCcwEiI6Oro6wlFJ1mZ9zmY7mkdD50vPnFRXBqfQLxyuO7rS3RC3MO1c2oLGTJLyvDeUkCxePyH1NlQeVRSQE+C/wF2PM+17zmgFFxpjTInId8LQxplt5deoYglLqohUV2mThebpscQvj+L7zk0Vgk5JbFq26QEh4nUoWbo8hICKBwHtAgncyADDGnPJ4/qmIPCsirY0xR73LKqVUtfBzfnndIhq6XHb+vKJCOJl2YcviyDZ7E6Si/HNlA5t6tCy8rg0V0rZOJYuKuuiEIHbk4xVgmzHm76WUaQccNsYYERkK+AGZJZVVSqka5+dvf0zXMsbeDtVTYQGc3H/hvSwOb4Hv/w1FBefKBoV43cvCoyuqaZs6myyq0kIYCdwObBKRDc603wDRAMaY54HJwIMiUgCcBaYZX/zhg1JK+Qc4X/KdgCvOn1dYACdTL7xL3qFN8P0nXski9Py75HkmjKatfTpZ6A/TlFKqKgrz4UTqhS2LzN12uik8V7ZRs5LPhGrVBZq0qlKycH0MQSmlGjz/QPuF3qrLhfOKk4X3taEOrIetH4IpOle2UXMI7wN3fepaK0ITglJK1ZSykkVBntOy8BjgLsxztUtJE4JSSrkhIAhad7UPH1E3fr6nlFKqxmlCUEopBWhCUEop5dCEoJRSCtCEoJRSyqEJQSmlFKAJQSmllEMTglJKKcBHr2UkIhlAykUu3hrwxctra1yVo3FVjsZVOfUxrhhjTJuqrNwnE0JViEhSVS/wVBM0rsrRuCpH46ocjatk2mWklFIK0ISglFLKUR8TwotuB1AKjatyNK7K0bgqR+MqQb0bQ1BKKXVx6mMLQSml1EXQhKCUUgqoQwlBRMaJyHYR2SUivyphfiMRWejMTxSRjh7zfu1M3y4i19RyXD8Tka0islFEvhaRGI95hSKywXl8VMtx3SkiGR7rv9dj3gwR2ek8ZtRyXP/wiGmHiJzwmFeT2+tVETkiIptLmS8i8owT90YRucRjXk1ur/Liinfi2SQiK0VkgMe8fc70DSJSrTcpr0BcY0XkpMf/63ce88rcB2o4rl94xLTZ2afCnHk1ub2iROQ/znfBFhF5uIQyruxj5zHG+PwD8Ad2A52BICAZ6O1V5iHgeef5NGCh87y3U74R0Mmpx78W47oMaOI8f7A4Luf1aRe3153AnBKWDQP2OH9bOs9b1lZcXuV/BLxa09vLqXsMcAmwuZT51wGfAQIMAxJrentVMK4RxesDri2Oy3m9D2jt0vYaC3xS1X2guuPyKnsj8E0tba/2wCXO81BgRwmfSVf2Mc9HXWkhDAV2GWP2GGPygAXAeK8y44E3nOfvAleIiDjTFxhjco0xe4FdTn21Epcx5j/GmGzn5WogsprWXaW4ynANsMQYc8wYcxxYAoxzKa5bgfnVtO4yGWOWAcfKKDIeeNNYq4EWItKemt1e5cZljFnprBdqb/+qyPYqTVX2zeqOqzb3r4PGmPXO8yxgGxDhVcyVfcxTXUkIEcB+j9dpXLgxfyhjjCkATgKtKrhsTcbl6R7sEUCxYBFJEpHVIjKhmmKqTFyTnKbpuyISVcllazIunK61TsA3HpNrantVRGmx1+T2qizv/csAX4rIOhGZ6UI8w0UkWUQ+E5E+zjSf2F4i0gT7pfqex+Ra2V5iu7MHAYles1zfxwJqolJ1IRG5DYgFLvWYHGOMSReRzsA3IrLJGLO7lkL6GJhvjMkVkfuxravLa2ndFTENeNcYU+gxzc3t5dNE5DJsQhjlMXmUs73aAktE5HvnCLo2rMf+v06LyHXAh0C3Wlp3RdwIrDDGeLYmanx7iUgINgn9xBhzqjrrrg51pYWQDkR5vI50ppVYRkQCgOZAZgWXrcm4EJErgUeAm4wxucXTjTHpzt89wFLsUUOtxGWMyfSI5WVgcEWXrcm4PEzDqzlfg9urIkqLvSa3V4WISH/s/3C8MSazeLrH9joCfED1dZWWyxhzyhhz2nn+KRAoIq3xge3lKGv/qpHtJSKB2GSQYIx5v4Qi7u9jNTEwUd0PbEtmD7YLoXggqo9XmVmcP6i8yHneh/MHlfdQfYPKFYlrEHYQrZvX9JZAI+d5a2An1TS4VsG42ns8nwisNucGsPY68bV0nofVVlxOuZ7YAT6pje3lsY6OlD5Iej3nD/itqentVcG4orHjYiO8pjcFQj2erwTG1WJc7Yr/f9gv1lRn21VoH6ipuJz5zbHjDE1ra3s57/1N4J9llHFtH/shhpqotEYCtSPwO7Bfro840x7FHnUDBAPvOB+ONUBnj2UfcZbbDlxby3F9BRwGNjiPj5zpI4BNzgdiE3BPLcf1GLDFWf9/gJ4ey97tbMddwF21GZfz+g/A417L1fT2mg8cBPKxfbT3AA8ADzjzBZjrxL0JiK2l7VVeXC8Dxz32ryRnemdnWyU7/+dHajmu2R7712o8ElZJ+0BtxeWUuRN7oonncjW9vUZhxyg2evyvrvOFfczzoZeuUEopBdSdMQSllFI1TBOCUkopQBOCUkophyYEpZRSgCYEpZRSDk0ISimlAE0ISimlHP8fgrygmGd2RUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min =  1.885806\n",
      "With Teacher Forcing\n",
      "****************************************************************************************************\n",
      "acc tf.Tensor(0.014008641, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "369 ----> 495\n",
      "407 ----> 447\n",
      "445 ----> 418\n",
      "483 ----> 449\n",
      "521 ----> 497\n",
      "559 ----> 541\n",
      "597 ----> 581\n",
      "635 ----> 618\n",
      "673 ----> 653\n",
      "711 ----> 690\n",
      "749 ----> 727\n",
      "787 ----> 768\n",
      "825 ----> 809\n",
      "863 ----> 849\n",
      "901 ----> 888\n",
      "939 ----> 926\n",
      "977 ----> 964\n",
      "1015 ----> 1003\n",
      "1053 ----> 1041\n",
      "1091 ----> 1079\n",
      "1129 ---->    \n",
      "1167 ---->    \n",
      "1205 ---->    \n",
      "\n",
      "true step: 38.0\n",
      "mean pred step 30.74\n",
      "median pred step 38.00\n",
      "True length: 23.0\n",
      "Predicted length: 20.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "152 ----> 293\n",
      "165 ----> 235\n",
      "178 ----> 202\n",
      "191 ----> 201\n",
      "204 ----> 215\n",
      "217 ----> 232\n",
      "230 ----> 248\n",
      "243 ----> 263\n",
      "256 ----> 276\n",
      "269 ----> 289\n",
      "282 ---->    \n",
      "295 ---->    \n",
      "308 ---->    \n",
      "321 ---->    \n",
      "334 ---->    \n",
      "347 ---->    \n",
      "\n",
      "true step: 13.0\n",
      "mean pred step -0.44\n",
      "median pred step 13.00\n",
      "True length: 16.0\n",
      "Predicted length: 10.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "110 ----> 215\n",
      "123 ----> 170\n",
      "136 ----> 149\n",
      "149 ----> 152\n",
      "162 ----> 166\n",
      "175 ----> 184\n",
      "188 ---->    \n",
      "201 ---->    \n",
      "214 ---->    \n",
      "227 ---->    \n",
      "240 ---->    \n",
      "253 ---->    \n",
      "\n",
      "true step: 13.0\n",
      "mean pred step -6.20\n",
      "median pred step 3.00\n",
      "True length: 12.0\n",
      "Predicted length: 6.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "321 ----> 385\n",
      "329 ----> 358\n",
      "337 ----> 343\n",
      "345 ----> 357\n",
      "353 ----> 377\n",
      "361 ----> 394\n",
      "369 ----> 405\n",
      "377 ----> 414\n",
      "385 ----> 423\n",
      "393 ----> 430\n",
      "401 ----> 438\n",
      "409 ----> 445\n",
      "417 ----> 453\n",
      "425 ----> 460\n",
      "433 ----> 467\n",
      "441 ---->    \n",
      "449 ---->    \n",
      "457 ---->    \n",
      "465 ---->    \n",
      "473 ---->    \n",
      "481 ---->    \n",
      "489 ---->    \n",
      "\n",
      "true step: 8.0\n",
      "mean pred step 5.86\n",
      "median pred step 8.00\n",
      "True length: 22.0\n",
      "Predicted length: 15.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Without Teacher Forcing\n",
      "****************************************************************************************************\n",
      "acc tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "708 ----> 706\n",
      "753 ----> 701\n",
      "798 ----> 682\n",
      "843 ----> 700\n",
      "888 ----> 731\n",
      "933 ----> 764\n",
      "978 ----> 797\n",
      "1023 ----> 829\n",
      "1068 ----> 860\n",
      "1113 ----> 889\n",
      "1158 ----> 917\n",
      "1203 ----> 943\n",
      "1248 ----> 969\n",
      "1293 ----> 994\n",
      "1338 ----> 1018\n",
      "1383 ----> 1041\n",
      "1428 ----> 1065\n",
      "1473 ----> 1091\n",
      "1518 ----> 1118\n",
      "1563 ----> 1146\n",
      "1608 ----> 1174\n",
      "1653 ----> 1202\n",
      "1698 ----> 1231\n",
      "1743 ----> 1260\n",
      "1788 ----> 1289\n",
      "1833 ----> 1319\n",
      "1878 ----> 1349\n",
      "1923 ----> 1379\n",
      "    ----> 1410\n",
      "\n",
      "true step: 45.0\n",
      "mean pred step 25.14\n",
      "median pred step 28.00\n",
      "True length: 28.0\n",
      "Predicted length: 29.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "724 ----> 435\n",
      "769 ----> 434\n",
      "814 ----> 430\n",
      "859 ----> 445\n",
      "904 ----> 469\n",
      "949 ----> 495\n",
      "994 ----> 521\n",
      "1039 ----> 546\n",
      "1084 ----> 571\n",
      "1129 ----> 596\n",
      "1174 ----> 620\n",
      "1219 ----> 644\n",
      "1264 ----> 670\n",
      "1309 ----> 698\n",
      "1354 ----> 725\n",
      "1399 ----> 753\n",
      "1444 ----> 781\n",
      "\n",
      "true step: 45.0\n",
      "mean pred step 21.62\n",
      "median pred step 25.00\n",
      "True length: 17.0\n",
      "Predicted length: 17.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "928 ----> 430\n",
      "967 ----> 428\n",
      "1006 ----> 424\n",
      "1045 ----> 440\n",
      "1084 ----> 463\n",
      "1123 ----> 489\n",
      "1162 ----> 514\n",
      "1201 ----> 539\n",
      "1240 ----> 564\n",
      "1279 ----> 589\n",
      "1318 ----> 613\n",
      "1357 ----> 637\n",
      "1396 ----> 664\n",
      "1435 ----> 691\n",
      "1474 ----> 719\n",
      "1513 ----> 747\n",
      "    ----> 775\n",
      "\n",
      "true step: 39.0\n",
      "mean pred step 21.56\n",
      "median pred step 25.00\n",
      "True length: 16.0\n",
      "Predicted length: 17.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "677 ----> 293\n",
      "712 ----> 292\n",
      "747 ----> 292\n",
      "782 ----> 303\n",
      "817 ----> 320\n",
      "    ----> 342\n",
      "    ----> 367\n",
      "    ----> 394\n",
      "    ----> 422\n",
      "    ----> 450\n",
      "\n",
      "true step: 35.0\n",
      "mean pred step 17.44\n",
      "median pred step 22.00\n",
      "True length: 5.0\n",
      "Predicted length: 10.0\n",
      "\n",
      " **************************************************************************************************** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sort_key(x):\n",
    "    try:\n",
    "        id_str, model = x\n",
    "        return min(model.track[\"loss_cv\"])\n",
    "    except:\n",
    "        return 1e10\n",
    "\n",
    "\n",
    "for id_str, ae in sorted(aes, key=sort_key):\n",
    "    if len(ae.track[\"loss_cv\"]) == 0: \n",
    "        continue\n",
    "\n",
    "\n",
    "    for key in ae.track:\n",
    "        if \"loss\" in key:\n",
    "            plt.plot(ae.track[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.title(id_str)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"min = \", min(ae.track[\"loss_cv\"]).numpy())\n",
    "\n",
    "    print(\"With Teacher Forcing\")\n",
    "    show_reconsturction(ae, max_show=4)\n",
    "\n",
    "    print(\"\\n\"*3)\n",
    "    print(\"Without Teacher Forcing\")\n",
    "    show_reconsturction(ae,  max_show=4, teacher_forcing=False)\n",
    "    print(\"\\n\"*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved/toy_seqs/models/encoder/assets\n",
      "INFO:tensorflow:Assets written to: saved/toy_seqs/models/decoder/assets\n",
      "INFO:tensorflow:Assets written to: saved/toy_seqs/models/len_decoder/assets\n"
     ]
    }
   ],
   "source": [
    "save_seq_vae(ae, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
